{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee43589-e8a0-41d1-be60-5100cd767b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('archive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ad3aab-bd4c-4116-88d4-92408d3c05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths to your original dataset and the destination folders for train and test data\n",
    "original_dataset_path = 'cell_images'\n",
    "train_dataset_path = 'train_data'  # Create this folder manually\n",
    "test_dataset_path = 'test_data'    # Create this folder manually\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "os.makedirs(train_dataset_path, exist_ok=True)\n",
    "os.makedirs(test_dataset_path, exist_ok=True)\n",
    "\n",
    "# List the subdirectories (classes) in the original dataset folder\n",
    "class_names = ['Parasitized', 'Uninfected']\n",
    "\n",
    "# Define the ratio of data to be used for testing (e.g., 0.2 for 20%)\n",
    "test_ratio = 0.3\n",
    "\n",
    "# Loop through each class\n",
    "for class_name in class_names:\n",
    "    class_folder = os.path.join(original_dataset_path, class_name)\n",
    "    images = os.listdir(class_folder)\n",
    "    num_images = len(images)\n",
    "    \n",
    "    # Calculate the number of images for testing\n",
    "    num_test_images = int(num_images * test_ratio)\n",
    "    \n",
    "    # Randomly select images for testing\n",
    "    test_images = random.sample(images, num_test_images)\n",
    "    \n",
    "    # Move the selected test images to the test folder\n",
    "    for image in test_images:\n",
    "        src_path = os.path.join(class_folder, image)\n",
    "        dst_path = os.path.join(test_dataset_path, class_name, image)\n",
    "        shutil.move(src_path, dst_path)\n",
    "    \n",
    "    # Move the remaining images to the train folder\n",
    "    remaining_images = [image for image in images if image not in test_images]\n",
    "    for image in remaining_images:\n",
    "        src_path = os.path.join(class_folder, image)\n",
    "        dst_path = os.path.join(train_dataset_path, class_name, image)\n",
    "        shutil.move(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cdb245-6fd8-4fa1-8d9f-0aaeed349b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48fb96a-d08d-40b5-bfff-93cf6cf88be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19292 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 64, 64\n",
    "# Data augmentation (optional but recommended)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train_data',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17be072e-e590-49b0-93a0-0128a7fcefb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8266 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'test_data',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5061ab7-3fc7-428d-816c-bdc4e0b007ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a539ad73-f4ed-4a9d-b1db-1209ef6f8a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 62, 62, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 29, 29, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 12, 12, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1307073 (4.99 MB)\n",
      "Trainable params: 1306625 (4.98 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Convolutional layers with batch normalization and max pooling\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Flatten layer\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Fully connected layers with dropout\n",
    "cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))  # Adding dropout for regularization\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))  # Adding dropout for regularization\n",
    "\n",
    "# Output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7a5eb-e6b4-487c-a5d0-48d30cfb9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(train_generator, validation_data = test_generator, epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1c1d68-e9b8-4274-8828-2d63afa78e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u120663/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "cnn.save('malaria_augmented_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b4450cd-c08a-40d8-86c8-f703c9e764e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from numpy.random import randn\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img,load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79dca63e-0b27-4d18-8138-1bd63f8fcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('malaria_augmented_model.h5')\n",
    "\n",
    "img1=load_img('cell_validation/Parasitized/C39P4thinF_original_IMG_20150622_111326_cell_1.png')\n",
    "img2=load_img('cell_validation/Uninfected/C58P19thinF_IMG_20150802_122520_cell_109.png')\n",
    "\n",
    "x1=img_to_array(img1)\n",
    "x2=img_to_array(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "941b0bf3-c6f5-46e0-afcb-d56e64e38926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "desired_img_shape = (64, 64)\n",
    "x1_resized = tf.image.resize(x1, desired_img_shape)\n",
    "x2_resized = tf.image.resize(x2, desired_img_shape)\n",
    "\n",
    "# Convert them to numpy arrays and reshape to (1, 64, 64, 3)\n",
    "x1_input = x1_resized.numpy().reshape(( 1,64, 64, 3))\n",
    "x2_input = x2_resized.numpy().reshape(( 1,64, 64, 3))\n",
    "\n",
    "# Now you can feed them into the model\n",
    "X1 = cnn.predict(x1_input)\n",
    "X2 = cnn.predict(x2_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa2d5a75-6329-4247-998e-c9320e10d93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " img1 malaria detected\n",
      "img 2 malaria detected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if X1==1:\n",
    "    print(' img1 malaria detected')\n",
    "elif X1==2:\n",
    "    print('img1 uninfected')\n",
    "else:\n",
    "    print('dont know')\n",
    "if X2==1:\n",
    "    print('img 2 malaria detected')\n",
    "elif X2==0:\n",
    "    print('img2 uninfected')\n",
    "else:\n",
    "    print('dont know')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b0f2b-5d8f-4527-9511-f7604f8d63b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
